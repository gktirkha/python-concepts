{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My goal, get all books with 2 star rating\n",
    "[https://toscrape.com/](https://toscrape.com/) is a website to practice web scraping\n",
    "\n",
    "___\n",
    "Libraries for web scrapping and storing data in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "book_base_url = \"https://books.toscrape.com/catalogue/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by extracting information of one book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url.format(1))         # Hitting Page 1\n",
    "soup = bs4.BeautifulSoup(response.text, \"lxml\")     # Using beautifulSoup to process response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "Libertarianism for Beginners\n",
      "https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "It's Only the Himalayas\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "products = soup.select(\".product_pod:has(p.star-rating.Two) a[title]\")      # inspecting the we page i got to know that all the info i need in in a tag, which is in product_pod class\n",
    "for product in products:\n",
    "    print(product.get(\"title\"))\n",
    "    book_url = book_base_url + product.get(\"href\")\n",
    "    print(book_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products Explanation\n",
    "\n",
    "- `.product_pod`: This part of the selector selects all elements with the class `product_pod`. It identifies elements with this specific class.\n",
    "\n",
    "- `:has(p.star-rating.Two)`: This is a custom selector using `:has()`. It selects elements that contain a `<p>` element with the class `star-rating` and text content \"Two\" as one of their descendants. Essentially, it selects elements with a specific child structure.\n",
    "\n",
    "- `a[title]`: This part of the selector further narrows down the selection to include only `<a>` elements that have a `title` attribute.\n",
    "\n",
    "So, when you put it all together, the `soup.select(\".product_pod:has(p.star-rating.Two) a[title]\")` selector will find `<a>` elements with a `title` attribute that are descendants of elements with the class `product_pod`, where these elements contain a `<p>` element with the class `star-rating` and the text content \"Two\" as one of their descendants.\n",
    "\n",
    "This selector is useful for targeting specific links within a webpage that have a particular structure and class hierarchy.\n",
    "\n",
    "___\n",
    "\n",
    "Now put this code in a for loop so that we can extract info for all pages\n",
    "by visiting an invalid page, i got to know that i will receive error 404 or i can say for a successful result response code is 200, so the code becomes \n",
    "> The execution time of cell below will depend on internet speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted data form 50 pages\n"
     ]
    }
   ],
   "source": [
    "page_counter = 0\n",
    "books = {}\n",
    "while True:\n",
    "    page_counter += 1\n",
    "    response = requests.get(base_url.format(page_counter))\n",
    "    if (response.status_code != 200):\n",
    "        page_counter -= 1\n",
    "        break\n",
    "\n",
    "    soup = bs4.BeautifulSoup(response.text, \"lxml\")\n",
    "    products = soup.select(\".product_pod:has(p.star-rating.Two) a[title]\")\n",
    "    for product in products:\n",
    "        book_title = product.get(\"title\")\n",
    "        book_url = book_base_url + product.get(\"href\")\n",
    "        books[book_title] = book_url\n",
    "\n",
    "print(f\"extracted data form {page_counter} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storing result in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"books.json\", 'w') as json_file:\n",
    "    json.dump(books, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
